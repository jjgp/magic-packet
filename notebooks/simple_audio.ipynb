{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUmmYyRQR7KB"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNXfhe2W45qk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "IS_COLAB = \"google.colab\" in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keWJL1c55RgD"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    module_dir = \"./magic-packet\"\n",
    "    if not os.path.exists(module_dir):\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"clone\",\n",
    "                \"-q\",\n",
    "                \"https://github.com/jjgp/magic-packet.git\",\n",
    "                module_dir,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    subprocess.run([\"pip\", \"-q\", \"install\", \"-e\", module_dir], capture_output=True)\n",
    "\n",
    "    content_dir = \"/content/magic-packet/\"\n",
    "    if content_dir not in sys.path:\n",
    "        sys.path.insert(0, \"/content/magic-packet/\")\n",
    "else:\n",
    "    sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11_tpxQHdg2B"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython import display\n",
    "\n",
    "import magicpacket.dataset.mini_speech_commands  # noqa: F401\n",
    "from magicpacket.dataset import features\n",
    "from magicpacket.models import simple_audio_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wswk6hrHxg73"
   },
   "outputs": [],
   "source": [
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1xWc6sDH66w"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "3290c77f8887474cb4cace149250da7c",
      "e21da7abfb824914a15c95ce5e6b563a",
      "d72fe601bbc049bd818d338e7e9dcd39",
      "cee54986fb894da29f1caf3db4f25f09",
      "ea0ffc980fc1440e8286b196af6b3ba5",
      "18c803123da348199501aa3bce8fff23",
      "17fbeab0aeb04054a7799c0e69dc2c08",
      "7b4284ea4e5c4cba8fecd8598f1809fa",
      "1fdeefa2a29a4b469f7990015b37fcb1",
      "f9b903ec30df426caf0e12a3f273f94b",
      "378189ec5ba64c73bf721ade6d8e7208",
      "079b9123319743709d033aa13b5481cf",
      "7bbbf995ecf3418986df6b0ca99c31e4",
      "fbcc0e70d2a7478fb488067f16f881cb",
      "9d3e34f7c5f5490f96a4182506820596",
      "39383a54f96442a2ae530fe2de0bedba",
      "20fc105cebb7426d808c081e30654d1a",
      "de32c7a8bc9e43029dfbcae7979a8dc7",
      "92c8655717b44ae7a12ce087e3f74800",
      "91bfbed85747442389897ec6136ad82a",
      "405c4700fb5e44b4be7562766abbae49",
      "9a4916cc6e924e7abd37ffb75f6f1d21",
      "cb9928e1a297454899598a4b2494962b",
      "64bd81bee328442ebec62617dac6c40e",
      "43611719bc224ff5bb2e38e0e8cd96ab",
      "ceea80587b7b4626adb81e74033c388c",
      "eba5c1bc8ed94514a93f7e292d5c321f",
      "d1e16d4a93c6410cbd629c404ac26c21",
      "4b8c6b87971346f29253dc47fc461278",
      "184d11d80ed944bb8a5a1a5911137088",
      "9fe5da14013d450eaaf111125cce4362",
      "2307a910ca1b4f5d852a9f21ef5b2a13",
      "e6ccb620b88b44518c99e5ab376ffb30",
      "ff28b5720ae44a3db225961f259dc29b",
      "842552cd9bc5462ca1dde11b7e210b1c",
      "3bb0cca885df4303afa30b7bd8e22cc3",
      "82720f2b7833420c9bf6bee76704ff28",
      "8e21019c7d44442fbaef4e0e542a7436",
      "584ef199c73d49c5b0f8c767222235c7",
      "80f8942b13044831aa87b9fb139253ea",
      "37bc5bb59931452ab010caba7046ea62",
      "3724eea00eb2438593f1a09a77fe812a",
      "82b6afe8582743aa95256a24eaa80895",
      "3d6b31637f684711afc8b997683b1fca",
      "9583460052fe4a7fa69ec5d23400b315",
      "1f4cc500345e40c7814b5817e94fa68b",
      "160b83369c224ffbb9d73f303acd1039",
      "e443b48aefce405c8cee226a2fd2b080",
      "0ab9e0bc880b41d29437f5455e1aaaf9",
      "419d6c14b60a46e091b1dc8a62c79fd3",
      "32e217b8ef4948109bd285099478808c",
      "68f8321488904d01be831d1a62dc3818",
      "6937399a3d5041f88b5f051c2223e015",
      "8089066e234a42f8bfc68d69cc719fd1",
      "c58d159874524982ad1bbf0b538d845b",
      "ddbe70c0f094478d8d6831957f76aa78",
      "8440780fb89845dfa67d15604394ce60",
      "ab372e8d9a0c4fcaa213ca552b69eef6",
      "78472143c88c43bd8a15d28ca4fc47f9",
      "061e0079e74546f599643d23e28cf982",
      "03afce3107624a7d8ff5e5c70f1da0d7",
      "d3bab935ff064d1e9a1165a8e981cb57",
      "5463aed136f441d0a4ecb11ab101f8b8",
      "28124612acf746f6b0688dcac7fa8ef2",
      "8641c3b874304917b5c930f36a1e7594",
      "1fde69be0417469883313418ff6e436f"
     ]
    },
    "id": "LkF6Wgp3bINr",
    "outputId": "dd319af1-0b5b-4160-db96-db98df696bc8"
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), ds_info = tfds.load(\n",
    "    \"mini_speech_commands\",\n",
    "    split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCUcrjhcfrxy"
   },
   "outputs": [],
   "source": [
    "def plot_from_ds(ds, ds_info, rows=3, cols=3):\n",
    "    n = rows * cols\n",
    "    _, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "\n",
    "    for i, example in enumerate(ds.take(n)):\n",
    "        audio, label = example[\"audio\"], example[\"label\"]\n",
    "        r = i // cols\n",
    "        c = i % cols\n",
    "        ax = axes[r][c]\n",
    "        normalized = features.normalize(audio)\n",
    "        ax.plot(normalized.numpy())\n",
    "        ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "        name = ds_info.features[\"label\"].names[label]\n",
    "        ax.set_title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "id": "BCWCb1gzhVnN",
    "outputId": "29b32e0a-f952-4643-9887-70bdd860a99e"
   },
   "outputs": [],
   "source": [
    "plot_from_ds(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTMtG5UWIKG7"
   },
   "source": [
    "# Feature extraction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BA2uqiux4V0"
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "    if len(spectrogram.shape) > 2:\n",
    "        assert len(spectrogram.shape) == 3\n",
    "        spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "    # Convert the frequencies to log scale and transpose, so that the time is\n",
    "    # represented on the x-axis (columns).\n",
    "    # Add an epsilon to avoid taking a log of zero.\n",
    "    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "Us1MdGfVINic",
    "outputId": "d06eb415-d98e-4b98-aac1-12c80a811018"
   },
   "outputs": [],
   "source": [
    "for example in train_ds.take(1):\n",
    "    audio, label = example[\"audio\"], example[\"label\"]\n",
    "    # the waveform is normalized to the range [-1, 1]\n",
    "    wavename = ds_info.features[\"label\"].names[label]\n",
    "    waveform = features.normalize(audio)\n",
    "    mfcc = features.mfcc(waveform)\n",
    "\n",
    "print(\"Name:\", wavename)\n",
    "print(\"Waveform shape:\", waveform.shape)\n",
    "print(\"Audio playback\")\n",
    "display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "id": "VICIM_ejI6x1",
    "outputId": "47c2060b-b6f0-464b-bb00-a0decb97b920"
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, figsize=(10, 12))\n",
    "\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title(wavename)\n",
    "axes[0].set_xlim([0, 16000])\n",
    "\n",
    "spectrogram = features.spectrogram(waveform)\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title(\"spectrogram\")\n",
    "\n",
    "mfcc = features.mfcc(S=spectrogram)\n",
    "height, width = mfcc.shape\n",
    "X = np.linspace(0, np.size(mfcc), num=width, dtype=int)\n",
    "Y = range(height)\n",
    "axes[2].pcolormesh(X, Y, mfcc.numpy())\n",
    "axes[2].set_title(\"mfcc\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj1tmbJrlTmJ"
   },
   "source": [
    "# Build and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwqfDMJiwKtH"
   },
   "source": [
    "## Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bty7YMN1lUon"
   },
   "outputs": [],
   "source": [
    "def get_mfcc_and_label(example):\n",
    "    audio, label = example[\"audio\"], example[\"label\"]\n",
    "    normalized = features.normalize(audio)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    mfcc = features.mfcc(normalized)[..., tf.newaxis]\n",
    "    return mfcc, label\n",
    "\n",
    "\n",
    "def preprocess_dataset(ds):\n",
    "    return ds.map(map_func=get_mfcc_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = preprocess_dataset(train_ds)\n",
    "val_ds = preprocess_dataset(val_ds)\n",
    "test_ds = preprocess_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSjk514iwITw"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUKJSw_WL_cA",
    "outputId": "d909d78f-b557-4957-be29-8bd662ce2958"
   },
   "outputs": [],
   "source": [
    "for mfcc, _ in train_ds.take(1):\n",
    "    input_shape = mfcc.shape\n",
    "print(\"Input shape:\", input_shape)\n",
    "\n",
    "n_labels = len(ds_info.features[\"label\"].names)\n",
    "model = simple_audio_model(train_ds, input_shape, n_labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1mmbsfUYyo2"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuS9nuvBwHd4"
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODHT5xWtKCMn"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-qlsgPnL-MZ"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S92GbNWFMUqd",
    "outputId": "19bddef9-e3b3-48a7-a09a-f82c768dc3a3"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "9bxfAFQiY24w",
    "outputId": "e16a8d89-dc82-4235-9181-a4469d7a6f81"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics[\"loss\"], metrics[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmjRV83GapCm"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7ORcRfy7J5i"
   },
   "outputs": [],
   "source": [
    "# TODO: use test_ds to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1l1OPtpW22Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "C1xWc6sDH66w",
    "nTMtG5UWIKG7",
    "HwqfDMJiwKtH"
   ],
   "name": "simple_audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
