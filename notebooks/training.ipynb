{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from howl.context import InferenceContext\n",
    "from howl.data.dataset.dataset import DatasetType, WakeWordDataset\n",
    "from howl.data.dataset.dataset_loader import WakeWordDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"hey_fire_fox\"\n",
    "DATASET_PATHS = (\n",
    "    f\"../data/raw/{DATASET}/{sample_type}\" for sample_type in (\"positive\", \"negative\")\n",
    ")\n",
    "SAMPLE_RATE = 16000\n",
    "TOKEN_TYPE = \"word\"\n",
    "VOCAB = [\"hey\", \"fire\", \"fox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = InferenceContext(VOCAB, token_type=TOKEN_TYPE, use_blank=False)\n",
    "loader = WakeWordDatasetLoader()\n",
    "ds_kwargs = dict(sample_rate=SAMPLE_RATE, mono=True, frame_labeler=ctx.labeler)\n",
    "\n",
    "ww_train_ds, ww_dev_ds, ww_test_ds = (\n",
    "    WakeWordDataset(metadata_list=[], set_type=DatasetType.TRAINING, **ds_kwargs),\n",
    "    WakeWordDataset(metadata_list=[], set_type=DatasetType.DEV, **ds_kwargs),\n",
    "    WakeWordDataset(metadata_list=[], set_type=DatasetType.TEST, **ds_kwargs),\n",
    ")\n",
    "for ds_path in DATASET_PATHS:\n",
    "    ds_path = Path(ds_path)\n",
    "    train_ds, dev_ds, test_ds = loader.load_splits(ds_path, **ds_kwargs)\n",
    "    ww_train_ds.extend(train_ds)\n",
    "    ww_dev_ds.extend(dev_ds)\n",
    "    ww_test_ds.extend(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ww_train_ds, ww_dev_ds, ww_test_ds:\n",
    "    ds.print_stats(\n",
    "        logger,\n",
    "        header=f\"Wake word dataset: {ds.set_type}\",\n",
    "        word_searcher=ctx.searcher,\n",
    "        compute_length=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ww_dev_ds, ww_test_ds:\n",
    "    pos_ds = ds.filter(lambda x: ctx.searcher.search(x.transcription), clone=True)\n",
    "    pos_ds.print_stats(\n",
    "        logger,\n",
    "        header=f\"Pos dataset: {pos_ds.set_type}\",\n",
    "        word_searcher=ctx.searcher,\n",
    "        compute_length=True,\n",
    "    )\n",
    "\n",
    "    neg_ds = ds.filter(lambda x: not ctx.searcher.search(x.transcription), clone=True)\n",
    "    neg_ds.print_stats(\n",
    "        logger,\n",
    "        header=f\"Neg dataset: {neg_ds.set_type}\",\n",
    "        word_searcher=ctx.searcher,\n",
    "        compute_length=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "258d31df22b017b55b7ed215ff7e70bf14711bb89d8b241a2c12fb1094a01a70"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('magic-packet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
